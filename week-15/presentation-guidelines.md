# Week 15: Student Presentations (Session 2) & Course Wrap-up

## Reference

> **Watt, J., Borhani, R., & Katsaggelos, A. K. (2020).** *Machine Learning Refined* (2nd ed.). Cambridge University Press.

---

## Presentation Overview

This is the final presentation session and course conclusion.

---

## Presentation Requirements

Same format as Week 14:
- **Duration**: 15-20 minutes per student/group
- **Q&A**: 5 minutes after each presentation
- See [Week 14 Guidelines](../week-14/presentation-guidelines.md) for full details

---

## Schedule

| Time | Presenter(s) | Topic |
|------|--------------|-------|
| 00:00 - 00:25 | TBD | TBD |
| 00:25 - 00:50 | TBD | TBD |
| 00:50 - 01:15 | TBD | TBD |
| 01:15 - 01:40 | TBD | TBD |

---

## Course Wrap-up

### Key Course Takeaways

1. **Mathematical Optimization** (Chapters 2-4)
   - Zero-order, first-order, and second-order methods
   - Gradient descent is fundamental to ML

2. **Linear Learning** (Chapters 5-9)
   - Regression and classification
   - Feature engineering and selection
   - Regularization for model selection

3. **Nonlinear Learning** (Chapters 10-14)
   - Feature transformation
   - Universal approximation
   - Kernel methods, neural networks, trees

### Course Learning Outcomes Achieved

| Outcome | Chapters | Assessment |
|---------|----------|------------|
| Modeling optimization problems | 2-4 | Assignments, Midterm |
| Interpretability of ML models | 5-9 | Assignments, Project |
| Working with large models | 12-14 | Project |
| Real-world data-driven modeling | All | Project |

---

## Final Project Submission

### Due Date

End of finals week (see syllabus for exact date)

### Deliverables

1. **Final Report** (5-10 pages)
   - Problem description
   - Methodology with textbook references
   - Results and analysis
   - Conclusions

2. **Code Repository**
   - Clean, documented code
   - README with instructions
   - Requirements file
   - Sample data or data access instructions

3. **Presentation Slides**
   - As presented in class

---

## Grading Summary

| Component | Weight |
|-----------|--------|
| Assignments | 50% |
| Midterm Exam | 20% |
| Project | 30% |

### Project Breakdown

| Part | Weight |
|------|--------|
| Presentation | 40% |
| Report | 35% |
| Code | 25% |

---

## Resources for Future Learning

### Textbooks

1. **Deep Learning**: Goodfellow, Bengio, & Courville (2016)
2. **Statistical Learning**: Hastie, Tibshirani, & Friedman (2009)
3. **Interpretable ML**: Molnar (2022) - Free online

### Online Courses

- Stanford CS229: Machine Learning
- Fast.ai: Practical Deep Learning
- Coursera: ML Specialization by Andrew Ng

### Tools

- **scikit-learn**: General ML
- **PyTorch/TensorFlow**: Deep learning
- **XGBoost/LightGBM**: Gradient boosting
- **Marimo**: Interactive notebooks

---

## Course Evaluation

Please complete the course evaluation on your student portal. Your feedback helps improve future offerings!

---

## Thank You!

It has been a pleasure teaching this course. Best wishes for your future endeavors in data-driven modeling and optimization!

**Contact for future questions**: harun.pirim@ndsu.edu

---

## Appendix: Textbook Chapter Summary

| Week | Topic | Chapter |
|------|-------|---------|
| 1 | Introduction to Machine Learning | Ch. 1 |
| 2 | Zero-Order Optimization | Ch. 2 |
| 3 | First-Order Optimization | Ch. 3 |
| 4 | Second-Order Optimization | Ch. 4 |
| 5 | Linear Regression | Ch. 5 |
| 6 | Linear Two-Class Classification | Ch. 6 |
| 7 | Linear Multi-Class Classification | Ch. 7 |
| 8 | Linear Unsupervised Learning | Ch. 8 |
| 9 | Feature Engineering | Ch. 9 |
| 10 | Nonlinear Feature Engineering | Ch. 10 |
| 11 | Feature Learning & Cross-Validation | Ch. 11 |
| 12 | Kernel Methods & Neural Networks | Ch. 12-13 |
| 13 | Tree-Based Learners | Ch. 14 |
| 14-15 | Student Presentations | â€” |
