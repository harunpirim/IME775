{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colab_badge"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harunpirim/IME775/blob/main/week-07/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
        "",
        "---",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown_0"
      },
      "source": [
        "# Week 7: Linear Multi-Class Classification\n",
        "**IME775: Data Driven Modeling and Optimization**\n",
        "ðŸ“– **Reference**: Watt, Borhani, & Katsaggelos (2020). *Machine Learning Refined* (2nd ed.), **Chapter 7**\n",
        "---\n",
        "## Learning Objectives\n",
        "- Extend binary classification to multiple classes\n",
        "- Implement one-versus-all (OvA) classification\n",
        "- Understand the softmax classifier\n",
        "- Apply multi-class quality metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown_2"
      },
      "source": [
        "## Introduction (Section 7.1)\n",
        "**Multi-Class Classification**: Predict label $y \\in \\{1, 2, \\ldots, C\\}$ where $C > 2$.\n",
        "### Examples\n",
        "- Digit recognition: $C = 10$ (0-9)\n",
        "- Object detection: Many categories\n",
        "- Disease diagnosis: Multiple conditions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown_3"
      },
      "source": [
        "## One-versus-All (OvA) Classification (Section 7.2)\n",
        "### Strategy\n",
        "Train $C$ binary classifiers, one for each class:\n",
        "- Classifier $c$: Class $c$ vs all others\n",
        "### Prediction\n",
        "$$\\hat{y} = \\arg\\max_{c \\in \\{1,\\ldots,C\\}} w_c^T \\tilde{x}$$\n",
        "Choose the class with highest score.\n",
        "### Training\n",
        "For each class $c$:\n",
        "- Positive examples: Class $c$\n",
        "- Negative examples: All other classes\n",
        "- Train binary classifier $w_c$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_4"
      },
      "outputs": [],
      "source": [
        "# Generate 3-class data\n",
        "np.random.seed(42)\n",
        "n_per_class = 50\n",
        "# Three clusters\n",
        "X1 = np.random.randn(n_per_class, 2) + np.array([0, 3])\n",
        "X2 = np.random.randn(n_per_class, 2) + np.array([-3, -1])\n",
        "X3 = np.random.randn(n_per_class, 2) + np.array([3, -1])\n",
        "X = np.vstack([X1, X2, X3])\n",
        "y = np.array([0]*n_per_class + [1]*n_per_class + [2]*n_per_class)\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "colors = ['blue', 'red', 'green']\n",
        "for c in range(3):\n",
        "    mask = y == c\n",
        "    ax.scatter(X[mask, 0], X[mask, 1], c=colors[c], s=60, \n",
        "               label=f'Class {c}', edgecolors='black')\n",
        "ax.set_xlabel('$x_1$')\n",
        "ax.set_ylabel('$x_2$')\n",
        "ax.set_title('3-Class Classification Problem (ML Refined, Chapter 7)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_5"
      },
      "outputs": [],
      "source": [
        "# One-vs-All classification\n",
        "from sklearn.preprocessing import label_binarize\n",
        "# Train OvA classifier\n",
        "clf = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "clf.fit(X, y)\n",
        "# Create decision boundary mesh\n",
        "xx, yy = np.meshgrid(np.linspace(-6, 6, 200), np.linspace(-4, 6, 200))\n",
        "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
        "ax2.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
        "ax2.contour(xx, yy, Z, colors='black', linewidths=1, alpha=0.5)\n",
        "colors = ['blue', 'red', 'green']\n",
        "for c in range(3):\n",
        "    mask = y == c\n",
        "    ax2.scatter(X[mask, 0], X[mask, 1], c=colors[c], s=60, \n",
        "               label=f'Class {c}', edgecolors='black')\n",
        "ax2.set_xlabel('$x_1$')\n",
        "ax2.set_ylabel('$x_2$')\n",
        "ax2.set_title('One-vs-All Decision Boundaries')\n",
        "ax2.legend()\n",
        "fig2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown_6"
      },
      "source": [
        "## Softmax Classifier (Section 7.5)\n",
        "### The Softmax Function\n",
        "$$P(y = c | x) = \\frac{e^{w_c^T \\tilde{x}}}{\\sum_{j=1}^{C} e^{w_j^T \\tilde{x}}}$$\n",
        "### Properties\n",
        "- Outputs valid probabilities (sum to 1)\n",
        "- Generalizes logistic regression to $C$ classes\n",
        "- All classifiers trained jointly\n",
        "### Cross-Entropy Cost\n",
        "$$g(W) = -\\frac{1}{P} \\sum_{p=1}^{P} \\log\\left(\\frac{e^{w_{y_p}^T \\tilde{x}_p}}{\\sum_{c=1}^{C} e^{w_c^T \\tilde{x}_p}}\\right)$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_7"
      },
      "outputs": [],
      "source": [
        "# Softmax visualization\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z))  # Numerical stability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown_8"
      },
      "source": [
        "## Multi-Class Quality Metrics (Section 7.6)\n",
        "### Confusion Matrix\n",
        "For $C$ classes, a $C \\times C$ matrix where entry $(i, j)$ counts predictions of class $j$ when true class is $i$.\n",
        "### Per-Class Metrics\n",
        "For each class $c$:\n",
        "- **Precision**: $\\frac{TP_c}{TP_c + FP_c}$\n",
        "- **Recall**: $\\frac{TP_c}{TP_c + FN_c}$\n",
        "### Averaging Strategies\n",
        "| Method | Description |\n",
        "|--------|-------------|\n",
        "| **Macro** | Average per-class metrics |\n",
        "| **Micro** | Compute globally across all classes |\n",
        "| **Weighted** | Weight by class frequency |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown_9"
      },
      "source": [
        "## Summary\n",
        "| Method | Description | Use Case |\n",
        "|--------|-------------|----------|\n",
        "| **One-vs-All** | $C$ binary classifiers | Simple, independent training |\n",
        "| **Softmax** | Joint probability model | Calibrated probabilities |\n",
        "---\n",
        "## References\n",
        "- **Primary**: Watt, J., Borhani, R., & Katsaggelos, A. K. (2020). *Machine Learning Refined* (2nd ed.), Chapter 7.\n",
        "- **Supplementary**: Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*, Chapter 4.\n",
        "## Next Week\n",
        "**Linear Unsupervised Learning & PCA** (Chapter 8): Dimensionality reduction and clustering.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "notebook",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}