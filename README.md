# IME775: Data Driven Modeling and Optimization

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![NDSU](https://img.shields.io/badge/NDSU-Graduate-006747?style=for-the-badge)

**A graduate course covering mathematical foundations and architectures of deep learning with applications to data-driven modeling and optimization**

</div>

---

## ðŸ“š Course Information

| | |
|---|---|
| **Credits** | 3 |
| **Prerequisites** | Graduate standing |
| **Instructor** | Harun Pirim, PhD |
| **Office** | ENG 106 |
| **Email** | harun.pirim@ndsu.edu |

## ðŸ“– Primary Textbook

> **Krishnendu Chaudhury. (2024).** *Math and Architectures of Deep Learning*. Manning Publications.

### Supplementary Textbook

> **Watt, J., Borhani, R., & Katsaggelos, A. K. (2020).** *Machine Learning Refined: Foundations, Algorithms, and Applications* (2nd ed.). Cambridge University Press.

Chapter PDFs available in the `2nd_ed/` folder.



## ðŸŽ¯ Learning Outcomes

1. Mathematical foundations (linear algebra, calculus, probability, Bayesian methods)
2. Neural network architectures (perceptrons, MLPs, CNNs) and training algorithms
3. Optimization techniques (SGD, Adam) and regularization methods
4. Computer vision: image classification and object detection
5. Generative models: autoencoders and variational autoencoders

## ðŸ“Š Grading

| Component | Weight |
|-----------|--------|
| Assignments | 40% |
| Quizzes | 10% |
| Midterm Exam | 20% |
| Project Presentation | 15% |
| Project Report (Paper/Article) | 15% |

---

## ðŸ“… Course Schedule

| Week | Topic | Reference | Materials |
|:----:|-------|-----------|-----------|
| 01 | Machine Learning Overview & Vectors, Matrices, Tensors | Ch. 1-2 | [ðŸ“ Notes](week-01/Lecture_Notes1.md) \| [ðŸ“„ PDF](week-01/Lecture_Notes1.pdf) \| [ðŸ± Cat Brain Demo](week-01/cat_brain_marimo.py) |
| 02 | Classifiers and Vector Calculus (Gradients, Hessians) | Ch. 3 | [ðŸ“ Notes](week-02/Lecture_Notes2.md) \| [ðŸ“„ PDF](week-02/Lecture_Notes2.pdf) \| [ðŸ“ Lecture 4](week-02/IME775_Lecture4.md) \| [ðŸ“„ Lecture 4 PDF](week-02/IME775_Lecture4.pdf) \| [ðŸ“ Hyperplanes](week-02/lecture_notes_hyperplanes_ml.md) \| [ðŸ“„ Hyperplanes PDF](week-02/lecture_notes_hyperplanes_ml.pdf) \| [ðŸ““ Notebooks](week-02/) |
| 03 | PCA, SVD, and Dimensionality Reduction | Ch. 4 | ðŸ”’ Coming Soon |
| 04 | Probability Distributions for Machine Learning | Ch. 5 | ðŸ”’ Coming Soon |
| 05 | Bayesian Tools: MLE, MAP, Entropy, KL Divergence | Ch. 6 | ðŸ”’ Coming Soon |
| 06 | Perceptrons, MLPs, and Universal Approximation | Ch. 7 | ðŸ”’ Coming Soon |
| 07 | Forward Propagation and Backpropagation | Ch. 8 | ðŸ”’ Coming Soon |
| 08 | Midterm Exam | â€” | ðŸ”’ Coming Soon |
| 09 | Loss Functions, Optimization (SGD, Adam), Regularization | Ch. 9 | ðŸ”’ Coming Soon |
| 10 | Convolutions in Neural Networks (1D, 2D, 3D) | Ch. 10 | ðŸ”’ Coming Soon |
| 11 | CNNs: LeNet, VGG, Inception, ResNet | Ch. 11 | ðŸ”’ Coming Soon |
| 12 | Object Detection: R-CNN, Fast/Faster R-CNN | Ch. 11 | ðŸ”’ Coming Soon |
| 13 | Manifolds, Autoencoders, and VAEs | Ch. 12-14 | ðŸ”’ Coming Soon |
| 14 | Student Project Presentations | â€” | ðŸ”’ Coming Soon |
| 15 | Student Project Presentations | â€” | ðŸ”’ Coming Soon |

---

## ðŸ› ï¸ Getting Started

### Prerequisites

```bash
# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Course Materials

Each week's folder contains:
- **Lecture Notes** (`.md`) - Markdown format for easy reading and version control
- **PDF** (`.pdf`) - Printable lecture notes
- **Python Scripts** (`.py`) - Standalone implementations
- **Marimo Notebooks** (`*_marimo.py`) - Interactive demos with widgets

> **Note:** Course materials are released progressively. Currently, Week 1 and Week 2 materials are available. Additional weeks will be released as the semester progresses.

## ðŸ“ Repository Structure

```
IME775/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ 2nd_ed/                      # ML Refined chapters (supplementary)
â”‚   â”œâ”€â”€ chapter_1.pdf
â”‚   â””â”€â”€ ...
â”œâ”€â”€ week-01/                     # âœ… Released
â”‚   â”œâ”€â”€ Lecture_Notes1.md        # Lecture notes (Markdown)
â”‚   â”œâ”€â”€ Lecture_Notes1.pdf       # Lecture notes (PDF)
â”‚   â”œâ”€â”€ cat_brain_pytorch.py     # Cat Brain model (standalone script)
â”‚   â””â”€â”€ cat_brain_marimo.py      # Cat Brain model (interactive notebook)
â””â”€â”€ week-02/                     # âœ… Released
    â”œâ”€â”€ Lecture_Notes2.md        # Lecture notes (Markdown)
    â”œâ”€â”€ Lecture_Notes2.pdf       # Lecture notes (PDF)
    â”œâ”€â”€ IME775_Lecture4.md       # Lecture 4 notes (Markdown)
    â”œâ”€â”€ IME775_Lecture4.pdf      # Lecture 4 notes (PDF)
    â”œâ”€â”€ lecture_notes_hyperplanes_ml.md  # Hyperplanes notes (Markdown)
    â”œâ”€â”€ lecture_notes_hyperplanes_ml.pdf  # Hyperplanes notes (PDF)
    â”œâ”€â”€ IME775_Lecture3-4_Notes.md
    â”œâ”€â”€ IME775_Lecture3-4_Problems.md
    â””â”€â”€ *.py                     # Marimo notebooks and Python scripts

Note: Additional weekly materials (week-03 through week-15) will be released progressively throughout the semester.
```

## ðŸ”§ Libraries & Tools

- **NumPy** - Numerical computing
- **Pandas** - Data manipulation
- **Scikit-learn** - Machine learning
- **PyTorch** - Deep learning
- **Matplotlib/Seaborn** - Visualization
- **Marimo** - Interactive notebooks

---

## ðŸ± Interactive Demos

This course includes interactive notebooks built with [Marimo](https://marimo.io/) for hands-on learning.

### Week 1: Cat Brain Model

The Cat Brain demo (`week-01/cat_brain_marimo.py`) implements the threat estimator from Chapter 1 with interactive widgets:

**Features:**
- ðŸŽ² Adjust random seed, sample sizes, and noise levels
- ðŸ“ Tune learning rate, epochs, and optimizer (SGD/Adam)
- ðŸ“Š Real-time training visualization (loss curve, parameter convergence)
- ðŸ”® Test inference with custom objects
- ðŸŽ¯ Adjustable decision threshold

**To run:**
```bash
# Activate virtual environment
source venv/bin/activate

# Run in edit mode (see code + output)
marimo edit week-01/cat_brain_marimo.py

# Or run in app mode (output only)
marimo run week-01/cat_brain_marimo.py
```

---

## ðŸ“– Primary Textbook Chapter Overview

> **Krishnendu Chaudhury. (2024).** *Math and Architectures of Deep Learning*. Manning Publications.

### Part I: Mathematical Foundations (Ch. 1-6)
- **Chapter 1**: Overview of Machine Learning and Deep Learning
  - Paradigm shift, function approximation view, cat brain example, regression vs. classification
- **Chapter 2**: Vectors, Matrices, and Tensors
  - Dot product, matrix multiplication, linear transforms, eigenvalues, eigenvectors, diagonalization, spectral decomposition
- **Chapter 3**: Classifiers and Vector Calculus
  - Decision boundaries, loss functions, gradients, Taylor series, Hessian matrix, convexity
- **Chapter 4**: Linear Algebraic Tools
  - PCA, dimensionality reduction, SVD, low-rank approximation, document retrieval with LSA
- **Chapter 5**: Probability Distributions
  - Random variables, joint/marginal probabilities, Gaussian, binomial, multinomial, Bernoulli, categorical
- **Chapter 6**: Bayesian Tools
  - Bayes' theorem, entropy, cross-entropy, KL divergence, MLE, MAP, Gaussian mixture models

### Part II: Neural Networks (Ch. 7-9)
- **Chapter 7**: Function Approximation with Neural Networks
  - Perceptrons, Heaviside function, hyperplanes, MLPs, XOR problem, Cybenko's universal approximation theorem
- **Chapter 8**: Training Neural Networks
  - Sigmoid/tanh activation, linear layers, forward propagation, backpropagation algorithm, gradient descent
- **Chapter 9**: Loss, Optimization, and Regularization
  - Cross-entropy, softmax, focal loss, hinge loss, SGD, momentum, AdaGrad, RMSprop, Adam, L1/L2 regularization, dropout

### Part III: Computer Vision (Ch. 10-11)
- **Chapter 10**: Convolutions in Neural Networks
  - 1D/2D/3D convolution, smoothing, edge detection, transposed convolution, pooling
- **Chapter 11**: Image Classification and Object Detection
  - LeNet, VGG, Inception, ResNet, R-CNN, Fast R-CNN, Faster R-CNN

### Part IV: Advanced Topics (Ch. 12-14)
- **Chapter 12**: Manifolds and Homeomorphism
  - Manifold properties, Hausdorff, second countable, neural networks as homeomorphisms
- **Chapter 13**: Fully Bayesian Parameter Estimation
  - Prior beliefs, conjugate priors, normal-gamma distribution, Bayesian inference
- **Chapter 14**: Latent Spaces and Generative Models
  - Autoencoders, variational autoencoders (VAEs), ELBO, reparameterization trick

---

## ðŸ“š Supplementary Materials (ML Refined)

Based on *Machine Learning Refined* (Watt et al., 2020), additional materials cover classical ML foundations:

| Topic | Week | ML Refined Chapter |
|-------|:----:|:------------------:|
| Introduction to Machine Learning | 01 | Ch. 1 |
| Zero-Order Optimization | 02 | Ch. 2 |
| Gradient Descent | 03 | Ch. 3 |
| Newton's Method | 04 | Ch. 4 |
| Linear Regression | 05 | Ch. 5 |
| Binary Classification | 06 | Ch. 6 |
| Multi-Class Classification | 07 | Ch. 7 |
| PCA & Unsupervised Learning | 08 | Ch. 8 |
| Feature Engineering | 09 | Ch. 9 |
| Nonlinear Features | 10 | Ch. 10 |
| Feature Learning | 11 | Ch. 11 |
| Kernel Methods | 12 | Ch. 12 |
| Tree-Based Methods | 13 | Ch. 14 |

---

## ðŸ“œ Course Policies

### Attendance
Attendance in classes is expected per NDSU Policy 333.

### Academic Honesty
NDSU Policy 335: Code of Academic Responsibility and Conduct applies. See [www.ndsu.edu/academichonesty](https://www.ndsu.edu/academichonesty).

### Disability Services
Students with disabilities are invited to contact [Disability Services](https://www.ndsu.edu/disabilityservices).

---

<div align="center">

**North Dakota State University** | Industrial & Manufacturing Systems Engineering

</div>
