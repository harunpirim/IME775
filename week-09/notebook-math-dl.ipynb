{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9: Convolutional Neural Networks (CNNs)",
    "**IME775: Data Driven Modeling and Optimization**",
    "ðŸ“– **Reference**: Krishnendu Chaudhury. *Math and Architectures of Deep Learning*, Chapter 9",
    "---",
    "## Learning Objectives",
    "- Understand the convolution operation mathematically",
    "- Master CNN building blocks: convolution, pooling, padding",
    "- Learn classic architectures",
    "- Visualize what CNNs learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Why Convolutions?",
    "**Problems with Fully Connected layers for images:**",
    "- Too many parameters (224Ã—224Ã—3 image â†’ 150M params for first layer!)",
    "- No spatial structure",
    "- No translation invariance",
    "**Convolution advantages:**",
    "- Parameter sharing (same filter everywhere)",
    "- Local connectivity",
    "- Translation equivariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 The Convolution Operation",
    "For 2D input $X$ and kernel $W$ of size $k \\times k$:",
    "$$(X * W)[i,j] = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} X[i+m, j+n] \\cdot W[m,n]$$",
    "**Sliding the filter across the image and computing dot products.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convolution step by step",
    "    k = W.shape[0]",
    "    if padding > 0:",
    "        X_padded = np.pad(X, padding, mode='constant')",
    "    else:",
    "        X_padded = X",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))",
    "    # Input with highlight",
    "    ax1 = axes[0]",
    "    ax1.imshow(X_padded, cmap='gray', vmin=0, vmax=1)",
    "    # Highlight the patch",
    "    rect = plt.Rectangle((step_j - 0.5, step_i - 0.5), k, k, ",
    "                         fill=False, edgecolor='red', linewidth=3)",
    "    ax1.add_patch(rect)",
    "    ax1.set_title(f'Input (patch at [{step_i},{step_j}])')",
    "    ax1.axis('off')",
    "    # Extracted patch",
    "    ax2 = axes[1]",
    "    patch = X_padded[step_i:step_i+k, step_j:step_j+k]",
    "    ax2.imshow(patch, cmap='gray', vmin=0, vmax=1)",
    "    for i in range(k):",
    "        for j in range(k):",
    "            ax2.text(j, i, f'{patch[i,j]:.1f}', ha='center', va='center', ",
    "                    fontsize=12, color='red' if patch[i,j] > 0.5 else 'blue')",
    "    ax2.set_title('Extracted Patch')",
    "    ax2.axis('off')",
    "    # Filter",
    "    ax3 = axes[2]",
    "    ax3.imshow(W, cmap='RdBu', vmin=-1, vmax=1)",
    "    for i in range(k):",
    "        for j in range(k):",
    "            ax3.text(j, i, f'{W[i,j]:.1f}', ha='center', va='center', fontsize=12)",
    "    ax3.set_title('Filter (Kernel)')",
    "    ax3.axis('off')",
    "    # Element-wise product",
    "    ax4 = axes[3]",
    "    product = patch * W",
    "    ax4.imshow(product, cmap='RdBu', vmin=-1, vmax=1)",
    "    for i in range(k):",
    "        for j in range(k):",
    "            ax4.text(j, i, f'{product[i,j]:.2f}', ha='center', va='center', fontsize=10)",
    "    ax4.set_title(f'Element-wise Product\\nSum = {product.sum():.2f}')",
    "    ax4.axis('off')",
    "    plt.tight_layout()",
    "    return fig",
    "# Create example",
    "X_demo = np.array([",
    "    [0, 0, 0, 0, 0, 0],",
    "    [0, 1, 1, 1, 0, 0],",
    "    [0, 1, 1, 1, 0, 0],",
    "    [0, 1, 1, 1, 0, 0],",
    "    [0, 0, 0, 0, 0, 0],",
    "    [0, 0, 0, 0, 0, 0],",
    "], dtype=float)",
    "W_demo = np.array([",
    "    [1, 0, -1],",
    "    [1, 0, -1],",
    "    [1, 0, -1],",
    "], dtype=float) / 3",
    "fig2 = visualize_conv_step(X_demo, W_demo, step_i=1, step_j=0, padding=0)",
    "fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Stride and Padding",
    "**Stride**: Step size when sliding the filter",
    "$$\\text{Output size} = \\lfloor \\frac{n - k}{\\text{stride}} \\rfloor + 1$$",
    "**Padding**: Add zeros around input",
    "$$\\text{Output size} = \\lfloor \\frac{n + 2p - k}{\\text{stride}} \\rfloor + 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Pooling Layers",
    "**Purpose**: Reduce spatial dimensions, add translation invariance",
    "| Type | Operation | Use |",
    "|------|-----------|-----|",
    "| Max | Take maximum | Most common |",
    "| Average | Take mean | Some architectures |",
    "| Global Avg | Mean over all spatial | Before classifier |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 CNN Architecture Evolution",
    "| Year | Architecture | Key Innovation |",
    "|------|--------------|----------------|",
    "| 1998 | LeNet-5 | First successful CNN |",
    "| 2012 | AlexNet | ReLU, Dropout, GPU |",
    "| 2014 | VGGNet | Small 3Ã—3 filters |",
    "| 2015 | ResNet | Skip connections |",
    "| 2017 | MobileNet | Depthwise separable |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature hierarchy",
    "fig5, axes5 = plt.subplots(1, 4, figsize=(16, 4))",
    "# Simulate different layer features",
    "np.random.seed(42)",
    "# Layer 1: Edges",
    "edge_filters = np.array([",
    "    [[1, 0, -1], [2, 0, -2], [1, 0, -1]],  # Vertical",
    "    [[1, 2, 1], [0, 0, 0], [-1, -2, -1]],  # Horizontal",
    "    [[0, 1, 2], [-1, 0, 1], [-2, -1, 0]],  # Diagonal",
    "])",
    "for i, filt in enumerate(edge_filters[:3]):",
    "    ax = axes5[0] if i == 0 else None",
    "axes5[0].set_title('Layer 1: Edges', fontsize=12)",
    "for i, filt in enumerate(edge_filters):",
    "    y_offset = i * 0.35",
    "    for ii in range(3):",
    "        for jj in range(3):",
    "            color = 'red' if filt[ii, jj] > 0 else ('blue' if filt[ii, jj] < 0 else 'gray')",
    "            axes5[0].add_patch(plt.Rectangle((jj/4 + 0.1, 0.55 - y_offset - ii/4), ",
    "                                              0.2, 0.2, facecolor=color, alpha=0.5))",
    "axes5[0].set_xlim(0, 1)",
    "axes5[0].set_ylim(0, 1)",
    "axes5[0].axis('off')",
    "# Layer 2-3: Textures/Parts",
    "axes5[1].text(0.5, 0.7, 'ðŸ”² Corners', fontsize=20, ha='center')",
    "axes5[1].text(0.5, 0.5, 'ã€°ï¸ Curves', fontsize=20, ha='center')",
    "axes5[1].text(0.5, 0.3, 'â¬› Patterns', fontsize=20, ha='center')",
    "axes5[1].set_title('Layer 2-3: Textures & Parts', fontsize=12)",
    "axes5[1].axis('off')",
    "# Layer 4: Parts",
    "axes5[2].text(0.5, 0.7, 'ðŸ‘ï¸ Eyes', fontsize=20, ha='center')",
    "axes5[2].text(0.5, 0.5, 'ðŸ‘ƒ Noses', fontsize=20, ha='center')",
    "axes5[2].text(0.5, 0.3, 'ðŸš— Wheels', fontsize=20, ha='center')",
    "axes5[2].set_title('Layer 4: Object Parts', fontsize=12)",
    "axes5[2].axis('off')",
    "# Layer 5: Objects",
    "axes5[3].text(0.5, 0.7, 'ðŸ˜º Cats', fontsize=20, ha='center')",
    "axes5[3].text(0.5, 0.5, 'ðŸš™ Cars', fontsize=20, ha='center')",
    "axes5[3].text(0.5, 0.3, 'ðŸ  Houses', fontsize=20, ha='center')",
    "axes5[3].set_title('Layer 5: Full Objects', fontsize=12)",
    "axes5[3].axis('off')",
    "plt.suptitle('CNN Feature Hierarchy: Simple â†’ Complex', fontsize=14, y=1.05)",
    "plt.tight_layout()",
    "fig5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6 Receptive Field",
    "The region of input that affects one output neuron.",
    "$$R = 1 + \\sum_{l=1}^{L} (k_l - 1) \\prod_{i=1}^{l-1} s_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary",
    "| Component | Purpose |",
    "|-----------|---------|",
    "| **Convolution** | Extract local features, parameter sharing |",
    "| **Stride** | Control downsampling |",
    "| **Padding** | Control output size |",
    "| **Pooling** | Reduce dimensions, translation invariance |",
    "| **Depth** | Learn hierarchical features |",
    "---",
    "## References",
    "- **Primary**: Krishnendu Chaudhury. *Math and Architectures of Deep Learning*, Chapter 9.",
    "- **LeNet**: LeCun et al. (1998)",
    "- **AlexNet**: Krizhevsky et al. (2012)",
    "- **VGG**: Simonyan & Zisserman (2015)",
    "## Connection to ML Refined Curriculum",
    "CNNs automate the feature engineering from Week 9:",
    "- Manual feature extraction â†’ Learned convolutional filters",
    "- Hierarchical representation learning"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}