{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_0"
      },
      "source": [
        "# Week 9: Convolutional Neural Networks (CNNs)\n",
        "**IME775: Data Driven Modeling and Optimization**\n",
        "ðŸ“– **Reference**: Krishnendu Chaudhury. *Math and Architectures of Deep Learning*, Chapter 9\n",
        "---\n",
        "## Learning Objectives\n",
        "- Understand the convolution operation mathematically\n",
        "- Master CNN building blocks: convolution, pooling, padding\n",
        "- Learn classic architectures\n",
        "- Visualize what CNNs learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_2"
      },
      "source": [
        "## 9.1 Why Convolutions?\n",
        "**Problems with Fully Connected layers for images:**\n",
        "- Too many parameters (224Ã—224Ã—3 image â†’ 150M params for first layer!)\n",
        "- No spatial structure\n",
        "- No translation invariance\n",
        "**Convolution advantages:**\n",
        "- Parameter sharing (same filter everywhere)\n",
        "- Local connectivity\n",
        "- Translation equivariance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_3"
      },
      "outputs": [],
      "source": [
        "# Demonstrate convolution operation\n",
        "def conv2d_manual(X, W, stride=1, padding=0):\n",
        "    \"\"\"Simple 2D convolution implementation.\"\"\"\n",
        "    k = W.shape[0]\n",
        "    if padding > 0:\n",
        "        X = np.pad(X, padding, mode='constant')\n",
        "    H, W_in = X.shape\n",
        "    H_out = (H - k) // stride + 1\n",
        "    W_out = (W_in - k) // stride + 1\n",
        "    output = np.zeros((H_out, W_out))\n",
        "    for i in range(H_out):\n",
        "        for j in range(W_out):\n",
        "            patch = X[i*stride:i*stride+k, j*stride:j*stride+k]\n",
        "            output[i, j] = np.sum(patch * W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_4"
      },
      "source": [
        "## 9.2 The Convolution Operation\n",
        "For 2D input $X$ and kernel $W$ of size $k \\times k$:\n",
        "$$(X * W)[i,j] = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} X[i+m, j+n] \\cdot W[m,n]$$\n",
        "**Sliding the filter across the image and computing dot products.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_5"
      },
      "outputs": [],
      "source": [
        "# Visualize convolution step by step\n",
        "def visualize_conv_step(X, W, step_i, step_j, padding=0):\n",
        "    k = W.shape[0]\n",
        "    if padding > 0:\n",
        "        X_padded = np.pad(X, padding, mode='constant')\n",
        "    else:\n",
        "        X_padded = X\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "    # Input with highlight\n",
        "    ax1 = axes[0]\n",
        "    ax1.imshow(X_padded, cmap='gray', vmin=0, vmax=1)\n",
        "    # Highlight the patch\n",
        "    rect = plt.Rectangle((step_j - 0.5, step_i - 0.5), k, k, \n",
        "                         fill=False, edgecolor='red', linewidth=3)\n",
        "    ax1.add_patch(rect)\n",
        "    ax1.set_title(f'Input (patch at [{step_i},{step_j}])')\n",
        "    ax1.axis('off')\n",
        "    # Extracted patch\n",
        "    ax2 = axes[1]\n",
        "    patch = X_padded[step_i:step_i+k, step_j:step_j+k]\n",
        "    ax2.imshow(patch, cmap='gray', vmin=0, vmax=1)\n",
        "    for i in range(k):\n",
        "        for j in range(k):\n",
        "            ax2.text(j, i, f'{patch[i,j]:.1f}', ha='center', va='center', \n",
        "                    fontsize=12, color='red' if patch[i,j] > 0.5 else 'blue')\n",
        "    ax2.set_title('Extracted Patch')\n",
        "    ax2.axis('off')\n",
        "    # Filter\n",
        "    ax3 = axes[2]\n",
        "    ax3.imshow(W, cmap='RdBu', vmin=-1, vmax=1)\n",
        "    for i in range(k):\n",
        "        for j in range(k):\n",
        "            ax3.text(j, i, f'{W[i,j]:.1f}', ha='center', va='center', fontsize=12)\n",
        "    ax3.set_title('Filter (Kernel)')\n",
        "    ax3.axis('off')\n",
        "    # Element-wise product\n",
        "    ax4 = axes[3]\n",
        "    product = patch * W\n",
        "    ax4.imshow(product, cmap='RdBu', vmin=-1, vmax=1)\n",
        "    for i in range(k):\n",
        "        for j in range(k):\n",
        "            ax4.text(j, i, f'{product[i,j]:.2f}', ha='center', va='center', fontsize=10)\n",
        "    ax4.set_title(f'Element-wise Product\\nSum = {product.sum():.2f}')\n",
        "    ax4.axis('off')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_6"
      },
      "source": [
        "## 9.3 Stride and Padding\n",
        "**Stride**: Step size when sliding the filter\n",
        "$$\\text{Output size} = \\lfloor \\frac{n - k}{\\text{stride}} \\rfloor + 1$$\n",
        "**Padding**: Add zeros around input\n",
        "$$\\text{Output size} = \\lfloor \\frac{n + 2p - k}{\\text{stride}} \\rfloor + 1$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_7"
      },
      "outputs": [],
      "source": [
        "# Demonstrate stride and padding effects\n",
        "fig3, axes3 = plt.subplots(2, 3, figsize=(15, 8))\n",
        "# Input image\n",
        "input_img = np.random.rand(8, 8)\n",
        "kernel = np.ones((3, 3)) / 9  # Average filter\n",
        "configs = [\n",
        "    ('Stride=1, Pad=0', 1, 0),\n",
        "    ('Stride=2, Pad=0', 2, 0),\n",
        "    ('Stride=1, Pad=1 (Same)', 1, 1),\n",
        "]\n",
        "# Original\n",
        "axes3[0, 0].imshow(input_img, cmap='viridis')\n",
        "axes3[0, 0].set_title(f'Input: {input_img.shape[0]}Ã—{input_img.shape[1]}')\n",
        "axes3[0, 0].axis('off')\n",
        "# Different configurations\n",
        "for idx, (name, stride, pad) in enumerate(configs):\n",
        "    if pad > 0:\n",
        "        padded = np.pad(input_img, pad, mode='constant')\n",
        "    else:\n",
        "        padded = input_img\n",
        "    k = kernel.shape[0]\n",
        "    H_out = (padded.shape[0] - k) // stride + 1\n",
        "    W_out = (padded.shape[1] - k) // stride + 1\n",
        "    output = np.zeros((H_out, W_out))\n",
        "    for i in range(H_out):\n",
        "        for j in range(W_out):\n",
        "            patch = padded[i*stride:i*stride+k, j*stride:j*stride+k]\n",
        "            output[i, j] = np.sum(patch * kernel)\n",
        "    if idx == 0:\n",
        "        ax = axes3[0, 1]\n",
        "    elif idx == 1:\n",
        "        ax = axes3[0, 2]\n",
        "    else:\n",
        "        ax = axes3[1, 0]\n",
        "    ax.imshow(output, cmap='viridis')\n",
        "    ax.set_title(f'{name}\\nOutput: {H_out}Ã—{W_out}')\n",
        "    ax.axis('off')\n",
        "# Show formula\n",
        "axes3[1, 1].text(0.5, 0.7, 'Output Size Formula:', ha='center', fontsize=14, fontweight='bold')\n",
        "axes3[1, 1].text(0.5, 0.4, r'$\\left\\lfloor \\frac{n + 2p - k}{s} \\right\\rfloor + 1$', \n",
        "                 ha='center', fontsize=20)\n",
        "axes3[1, 1].text(0.5, 0.15, 'n=input, k=kernel, p=padding, s=stride', ha='center', fontsize=11)\n",
        "axes3[1, 1].axis('off')\n",
        "# Example calculation\n",
        "axes3[1, 2].text(0.5, 0.8, 'Example: 224Ã—224 input', ha='center', fontsize=12, fontweight='bold')\n",
        "axes3[1, 2].text(0.5, 0.6, '7Ã—7 kernel, stride=2, pad=3', ha='center', fontsize=11)\n",
        "axes3[1, 2].text(0.5, 0.4, r'$\\left\\lfloor \\frac{224 + 6 - 7}{2} \\right\\rfloor + 1$', \n",
        "                 ha='center', fontsize=16)\n",
        "axes3[1, 2].text(0.5, 0.2, '= 112Ã—112 output', ha='center', fontsize=14, fontweight='bold', color='red')\n",
        "axes3[1, 2].axis('off')\n",
        "plt.tight_layout()\n",
        "fig3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_8"
      },
      "source": [
        "## 9.4 Pooling Layers\n",
        "**Purpose**: Reduce spatial dimensions, add translation invariance\n",
        "| Type | Operation | Use |\n",
        "|------|-----------|-----|\n",
        "| Max | Take maximum | Most common |\n",
        "| Average | Take mean | Some architectures |\n",
        "| Global Avg | Mean over all spatial | Before classifier |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_9"
      },
      "outputs": [],
      "source": [
        "# Demonstrate pooling\n",
        "def max_pool(X, pool_size=2, stride=2):\n",
        "    H, W = X.shape\n",
        "    H_out = (H - pool_size) // stride + 1\n",
        "    W_out = (W - pool_size) // stride + 1\n",
        "    output = np.zeros((H_out, W_out))\n",
        "    for i in range(H_out):\n",
        "        for j in range(W_out):\n",
        "            patch = X[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size]\n",
        "            output[i, j] = patch.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_10"
      },
      "source": [
        "## 9.5 CNN Architecture Evolution\n",
        "| Year | Architecture | Key Innovation |\n",
        "|------|--------------|----------------|\n",
        "| 1998 | LeNet-5 | First successful CNN |\n",
        "| 2012 | AlexNet | ReLU, Dropout, GPU |\n",
        "| 2014 | VGGNet | Small 3Ã—3 filters |\n",
        "| 2015 | ResNet | Skip connections |\n",
        "| 2017 | MobileNet | Depthwise separable |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_11"
      },
      "outputs": [],
      "source": [
        "# Visualize feature hierarchy\n",
        "fig5, axes5 = plt.subplots(1, 4, figsize=(16, 4))\n",
        "# Simulate different layer features\n",
        "np.random.seed(42)\n",
        "# Layer 1: Edges\n",
        "edge_filters = np.array([\n",
        "    [[1, 0, -1], [2, 0, -2], [1, 0, -1]],  # Vertical\n",
        "    [[1, 2, 1], [0, 0, 0], [-1, -2, -1]],  # Horizontal\n",
        "    [[0, 1, 2], [-1, 0, 1], [-2, -1, 0]],  # Diagonal\n",
        "])\n",
        "for i, filt in enumerate(edge_filters[:3]):\n",
        "    ax = axes5[0] if i == 0 else None\n",
        "axes5[0].set_title('Layer 1: Edges', fontsize=12)\n",
        "for i, filt in enumerate(edge_filters):\n",
        "    y_offset = i * 0.35\n",
        "    for ii in range(3):\n",
        "        for jj in range(3):\n",
        "            color = 'red' if filt[ii, jj] > 0 else ('blue' if filt[ii, jj] < 0 else 'gray')\n",
        "            axes5[0].add_patch(plt.Rectangle((jj/4 + 0.1, 0.55 - y_offset - ii/4), \n",
        "                                              0.2, 0.2, facecolor=color, alpha=0.5))\n",
        "axes5[0].set_xlim(0, 1)\n",
        "axes5[0].set_ylim(0, 1)\n",
        "axes5[0].axis('off')\n",
        "# Layer 2-3: Textures/Parts\n",
        "axes5[1].text(0.5, 0.7, 'ðŸ”² Corners', fontsize=20, ha='center')\n",
        "axes5[1].text(0.5, 0.5, 'ã€°ï¸ Curves', fontsize=20, ha='center')\n",
        "axes5[1].text(0.5, 0.3, 'â¬› Patterns', fontsize=20, ha='center')\n",
        "axes5[1].set_title('Layer 2-3: Textures & Parts', fontsize=12)\n",
        "axes5[1].axis('off')\n",
        "# Layer 4: Parts\n",
        "axes5[2].text(0.5, 0.7, 'ðŸ‘ï¸ Eyes', fontsize=20, ha='center')\n",
        "axes5[2].text(0.5, 0.5, 'ðŸ‘ƒ Noses', fontsize=20, ha='center')\n",
        "axes5[2].text(0.5, 0.3, 'ðŸš— Wheels', fontsize=20, ha='center')\n",
        "axes5[2].set_title('Layer 4: Object Parts', fontsize=12)\n",
        "axes5[2].axis('off')\n",
        "# Layer 5: Objects\n",
        "axes5[3].text(0.5, 0.7, 'ðŸ˜º Cats', fontsize=20, ha='center')\n",
        "axes5[3].text(0.5, 0.5, 'ðŸš™ Cars', fontsize=20, ha='center')\n",
        "axes5[3].text(0.5, 0.3, 'ðŸ  Houses', fontsize=20, ha='center')\n",
        "axes5[3].set_title('Layer 5: Full Objects', fontsize=12)\n",
        "axes5[3].axis('off')\n",
        "plt.suptitle('CNN Feature Hierarchy: Simple â†’ Complex', fontsize=14, y=1.05)\n",
        "plt.tight_layout()\n",
        "fig5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_12"
      },
      "source": [
        "## 9.6 Receptive Field\n",
        "The region of input that affects one output neuron.\n",
        "$$R = 1 + \\sum_{l=1}^{L} (k_l - 1) \\prod_{i=1}^{l-1} s_i$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_13"
      },
      "outputs": [],
      "source": [
        "# Calculate receptive field\n",
        "def calc_receptive_field(layers):\n",
        "    \"\"\"\n",
        "    layers: list of (kernel_size, stride) tuples\n",
        "    \"\"\"\n",
        "    rf = 1\n",
        "    stride_product = 1\n",
        "    for k, s in layers:\n",
        "        rf = rf + (k - 1) * stride_product\n",
        "        stride_product *= s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_14"
      },
      "source": [
        "## Summary\n",
        "| Component | Purpose |\n",
        "|-----------|---------|\n",
        "| **Convolution** | Extract local features, parameter sharing |\n",
        "| **Stride** | Control downsampling |\n",
        "| **Padding** | Control output size |\n",
        "| **Pooling** | Reduce dimensions, translation invariance |\n",
        "| **Depth** | Learn hierarchical features |\n",
        "---\n",
        "## References\n",
        "- **Primary**: Krishnendu Chaudhury. *Math and Architectures of Deep Learning*, Chapter 9.\n",
        "- **LeNet**: LeCun et al. (1998)\n",
        "- **AlexNet**: Krizhevsky et al. (2012)\n",
        "- **VGG**: Simonyan & Zisserman (2015)\n",
        "## Connection to ML Refined Curriculum\n",
        "CNNs automate the feature engineering from Week 9:\n",
        "- Manual feature extraction â†’ Learned convolutional filters\n",
        "- Hierarchical representation learning\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}